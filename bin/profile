#!/usr/bin/env ruby
# frozen_string_literal: true

# Profile TypeGuessr performance using stackprof
#
# Usage:
#   bin/profile [options]
#
# Options:
#   --target=indexing|inference|all  What to profile (default: all)
#   --mode=cpu|wall|object           Profiling mode (default: cpu)
#   --limit=N                        Max files to process (default: all)
#   --samples=N                      Number of inference samples (default: 100)
#   --output=path                    Output file path (default: tmp/stackprof-<target>.dump)
#   --interval=N                     Sampling interval in microseconds (default: 10)
#   --path=PATH                      Project directory to profile (default: current)
#   --report                         Generate markdown report
#
# Examples:
#   bin/profile                               # Profile everything
#   bin/profile --target=indexing             # Profile indexing only
#   bin/profile --target=inference            # Profile type inference only
#   bin/profile --mode=object                 # Profile object allocations
#   bin/profile --report                      # Generate markdown report
#   bin/profile --path=/path/to/rails         # Profile a different project

require "bundler/setup"
require "stackprof"
require "prism"
require "optparse"
require "fileutils"
require "ruby_indexer/ruby_indexer"

# Load TypeGuessr core components
require_relative "../lib/type_guessr/core/ir/nodes"
require_relative "../lib/type_guessr/core/types"
require_relative "../lib/type_guessr/core/converter/prism_converter"
require_relative "../lib/type_guessr/core/index/location_index"
require_relative "../lib/type_guessr/core/inference/resolver"
require_relative "../lib/type_guessr/core/registry/signature_registry"
require_relative "../lib/type_guessr/core/registry/method_registry"
require_relative "../lib/type_guessr/core/registry/instance_variable_registry"
require_relative "../lib/type_guessr/core/registry/class_variable_registry"
require_relative "../lib/type_guessr/core/type_simplifier"
require_relative "lib/tool_setup"

module ProfileIndexing
  # Runs stackprof profiling on TypeGuessr
  class Runner
    TARGET_DESCRIPTIONS = {
      indexing: "indexing only",
      inference: "inference only",
      all: "indexing + inference"
    }.freeze

    def initialize(target:, mode:, limit:, samples:, output:, interval:, path:, report:)
      @target = target.to_sym
      @mode = mode.to_sym
      @limit = limit
      @samples = samples
      @output = output || default_output
      @interval = interval
      @path = path
      @report = report
      @converter = TypeGuessr::Core::Converter::PrismConverter.new
      @location_index = TypeGuessr::Core::Index::LocationIndex.new
      @results = {}
    end

    def run
      puts "Project path: #{@path || Dir.pwd}"
      files = ToolSetup.collect_indexable_files(path: @path)
      puts "Found #{files.size} indexable files (same as ruby-lsp)"

      if @limit && @limit < files.size
        files = files.first(@limit)
        puts "Processing first #{@limit} files (use --limit to change)"
      end

      FileUtils.mkdir_p(File.dirname(@output))

      puts "Building RubyIndexer for code_index..."
      @code_index = ToolSetup.build_code_index(files)
      @infra = ToolSetup.build_infrastructure(@code_index)
      puts "code_index ready."

      case @target
      when :indexing
        profile_indexing(files)
      when :inference
        # Need to index first without profiling
        puts "\nPre-indexing files (not profiled)..."
        index_files_silent(files)
        profile_inference
      when :all
        profile_all(files)
      end

      generate_report if @report
    end

    private def default_output
      "tmp/stackprof-#{@target}.dump"
    end

    # Profile indexing only
    def profile_indexing(files)
      puts "\n=== Profiling: Indexing ==="
      puts "Mode: #{@mode}, Interval: #{@interval}μs"
      puts "-" * 50

      result = StackProf.run(mode: @mode, interval: @interval, raw: true) do
        index_files(files)
      end

      @results[:indexing] = result
      print_result("Indexing", result)
      save_result(result, @output)
      print_indexing_stats
    end

    # Profile inference only (assumes already indexed)
    def profile_inference
      puts "\n=== Profiling: Type Inference ==="
      puts "Mode: #{@mode}, Interval: #{@interval}μs, Samples: #{@samples}"
      puts "-" * 50

      # Collect sample nodes for inference
      sample_nodes = collect_inference_samples

      if sample_nodes.empty?
        puts "No nodes to sample for inference!"
        return
      end

      puts "Collected #{sample_nodes.size} nodes for inference sampling"

      result = StackProf.run(mode: @mode, interval: @interval, raw: true) do
        run_inference(sample_nodes)
      end

      @results[:inference] = result
      print_result("Inference", result)
      save_result(result, @output.sub(".dump", "-inference.dump"))
      print_inference_stats(sample_nodes)
    end

    # Profile everything (indexing and inference separately, with both CPU and wall time)
    def profile_all(files)
      # Phase 1: Indexing (CPU)
      puts "\n=== Profiling: Indexing (CPU) ==="
      puts "Mode: #{@mode}, Interval: #{@interval}μs"
      puts "-" * 50

      indexing_result = StackProf.run(mode: @mode, interval: @interval, raw: true) do
        index_files(files)
      end

      @results[:indexing] = indexing_result
      print_result("Indexing (CPU)", indexing_result)
      save_result(indexing_result, @output.sub(".dump", "-indexing.dump"))
      print_indexing_stats

      # Phase 1b: Indexing (Wall) - if CPU mode, also run wall time
      if @mode == :cpu
        puts "\n=== Profiling: Indexing (Wall Time) ==="
        puts "Mode: wall, Interval: #{@interval}μs"
        puts "-" * 50

        # Reset for wall time profiling
        reset_state
        indexing_wall_result = StackProf.run(mode: :wall, interval: @interval, raw: true) do
          index_files(files)
        end

        @results[:indexing_wall] = indexing_wall_result
        print_result("Indexing (Wall)", indexing_wall_result)
        save_result(indexing_wall_result, @output.sub(".dump", "-indexing-wall.dump"))
      end

      # Phase 2: Inference (CPU)
      puts "\n=== Profiling: Inference (CPU) ==="
      puts "Mode: #{@mode}, Interval: #{@interval}μs, Samples: #{@samples}"
      puts "-" * 50

      sample_nodes = collect_inference_samples
      if sample_nodes.empty?
        puts "No nodes to sample for inference!"
        return
      end

      puts "Collected #{sample_nodes.size} nodes for inference sampling"

      inference_result = StackProf.run(mode: @mode, interval: @interval, raw: true) do
        run_inference(sample_nodes)
      end

      @results[:inference] = inference_result
      print_result("Inference (CPU)", inference_result)
      save_result(inference_result, @output.sub(".dump", "-inference.dump"))
      print_inference_stats(sample_nodes)

      # Phase 2b: Inference (Wall) - if CPU mode, also run wall time
      return unless @mode == :cpu

      puts "\n=== Profiling: Inference (Wall Time) ==="
      puts "Mode: wall, Interval: #{@interval}μs"
      puts "-" * 50

      inference_wall_result = StackProf.run(mode: :wall, interval: @interval, raw: true) do
        run_inference(sample_nodes)
      end

      @results[:inference_wall] = inference_wall_result
      print_result("Inference (Wall)", inference_wall_result)
      save_result(inference_wall_result, @output.sub(".dump", "-inference-wall.dump"))
    end

    def reset_state
      @converter = TypeGuessr::Core::Converter::PrismConverter.new
      @location_index = TypeGuessr::Core::Index::LocationIndex.new
      @infra = ToolSetup.build_infrastructure(@code_index)
    end

    def index_files(files)
      files.each do |file_path|
        process_file(file_path)
      rescue StandardError => e
        warn "Error processing #{file_path}: #{e.message}"
      end
      @location_index.finalize!
    end

    def index_files_silent(files)
      files.each do |file_path|
        process_file(file_path)
      rescue StandardError
        # Ignore errors during pre-indexing
      end
      @location_index.finalize!
    end

    def process_file(file_path)
      source = File.read(file_path)
      parsed = Prism.parse(source)
      return unless parsed.value

      @location_index.remove_file(file_path)

      context = ToolSetup.build_context(@infra, file_path: file_path, location_index: @location_index)

      parsed.value.statements&.body&.each do |stmt|
        @converter.convert(stmt, context)
      end
    end

    def should_sample_node?(node)
      # Sample nodes that are interesting for type inference
      case node
      when TypeGuessr::Core::IR::DefNode,
           TypeGuessr::Core::IR::LocalWriteNode,
           TypeGuessr::Core::IR::LocalReadNode,
           TypeGuessr::Core::IR::ParamNode,
           TypeGuessr::Core::IR::CallNode
        true
      else
        false
      end
    end

    def collect_inference_samples
      # Collect all nodes from location_index that are interesting for inference
      all_nodes = []
      @location_index.each_node do |node, scope_id|
        all_nodes << [node, scope_id] if should_sample_node?(node)
      end

      return [] if all_nodes.empty?

      # Sample evenly from the indexed nodes
      step = [all_nodes.size / @samples, 1].max
      all_nodes.each_slice(step).map(&:first).first(@samples)
    end

    def run_inference(sample_nodes)
      resolver = @infra.resolver
      sample_nodes.each do |(node, _scope_id)|
        resolver.infer(node)
      rescue StandardError
        # Ignore inference errors during profiling
      end
    end

    def print_result(label, result)
      puts "\n#{label} Profile:"
      StackProf::Report.new(result).print_text($stdout)
    end

    def save_result(result, path)
      File.binwrite(path, Marshal.dump(result))
      puts "\n#{"-" * 50}"
      puts "Profile saved to: #{path}"
      puts "\nTo view detailed report:"
      puts "  stackprof #{path}"
      puts "  stackprof --d3-flamegraph #{path} > #{path.sub(".dump", ".html")}"
    end

    def print_indexing_stats
      stats = @location_index.stats
      puts "\nIndexing Statistics:"
      puts "  Files indexed: #{stats[:files_count]}"
      puts "  Total nodes: #{stats[:total_nodes]}"
    end

    def print_inference_stats(sample_nodes)
      puts "\nInference Statistics:"
      puts "  Nodes sampled: #{sample_nodes.size}"

      # Count by node type
      by_type = sample_nodes.group_by { |node, _| node.class.name.split("::").last }
      by_type.each do |type, nodes|
        puts "    #{type}: #{nodes.size}"
      end
    end

    def generate_report
      puts "\n=== Generating Markdown Report ==="

      report_path = "tmp/profile-report.md"
      File.write(report_path, build_report_content)
      puts "Report saved to: #{report_path}"
    end

    def build_report_content
      <<~MARKDOWN
        # TypeGuessr Performance Profile Report

        Generated: #{Time.now.strftime("%Y-%m-%d %H:%M:%S")}

        ## Configuration

        - **Target:** #{@target} (#{target_description})
        - **Mode:** #{@mode} (#{@interval}μs interval)
        - **Files indexed:** #{@location_index.stats[:files_count]}
        - **Total nodes:** #{@location_index.stats[:total_nodes]}
        - **Inference samples:** #{@samples}

        ---

        #{indexing_report_section}

        #{inference_report_section}

        ## Call Graph Analysis

        ### Indexing Pipeline

        ```
        ProfileIndexing::Runner#index_files
          └── ProfileIndexing::Runner#process_file
                ├── Prism.parse
                └── PrismConverter#convert
                      ├── convert_class_or_module
                      │     ├── convert_def
                      │     ├── convert_array_literal
                      │     └── convert_call
                      └── convert_loc
                            └── Prism::Source#find_line
        ```

        ### Inference Pipeline

        ```
        Resolver#infer
          ├── infer_call
          │     └── RBSProvider#get_method_signatures
          │           └── RBS::DefinitionBuilder
          ├── infer_local_write
          └── infer_local_read
        ```

        ---

        #{optimization_recommendations_section}

        ---

        ## Generated Artifacts

        | File | Description |
        |------|-------------|
        #{dump_files_section}

        ## How to Further Analyze

        ```bash
        # View detailed text report
        stackprof tmp/stackprof-all-indexing.dump
        stackprof tmp/stackprof-all-inference.dump

        # Analyze specific method
        stackprof tmp/stackprof-all-indexing.dump --method 'PrismConverter#convert_loc'

        # Walk call tree for a method
        stackprof tmp/stackprof-all-indexing.dump --method 'Prism::Source#find_line' --walk

        # Generate interactive flamegraph
        stackprof --d3-flamegraph tmp/stackprof-all-indexing.dump > tmp/flamegraph-indexing.html
        stackprof --d3-flamegraph tmp/stackprof-all-inference.dump > tmp/flamegraph-inference.html
        ```
      MARKDOWN
    end

    def indexing_report_section
      result = @results[:indexing]
      return "## Indexing\n\nNo indexing profile data available.\n" unless result

      frames = extract_top_frames(result)
      gc_stats = extract_gc_stats(result)

      section = <<~SECTION
        ## Indexing Profile

        ### Key Metrics (CPU)

        | Metric | Value |
        |--------|-------|
        | Total samples | #{result[:samples]} |
        | GC samples | #{gc_stats[:total]} (#{gc_stats[:percent]}%) |
        | Miss rate | #{format("%.2f%%", (result[:missed_samples] || 0).to_f / [result[:samples], 1].max * 100)} |

        ### Top CPU Bottlenecks

        #{top_bottlenecks_section(frames, result, :indexing)}

      SECTION

      # Add wall time analysis if available
      wall_result = @results[:indexing_wall]
      if wall_result
        wall_frames = extract_top_frames(wall_result)
        io_analysis = analyze_io_wait(result, wall_result)

        section += <<~WALL

          ### Wall Time Analysis

          #{io_analysis}

          ### Top Wall Time Bottlenecks

          #{top_bottlenecks_section(wall_frames, wall_result, :indexing)}

        WALL
      end

      "#{section}---\n\n"
    end

    def inference_report_section
      result = @results[:inference]
      return "## Inference\n\nNo inference profile data available.\n" unless result

      frames = extract_top_frames(result)
      gc_stats = extract_gc_stats(result)

      section = <<~SECTION
        ## Inference Profile

        ### Key Metrics (CPU)

        | Metric | Value |
        |--------|-------|
        | Total samples | #{result[:samples]} |
        | GC samples | #{gc_stats[:total]} (#{gc_stats[:percent]}%) |
        | Miss rate | #{format("%.2f%%", (result[:missed_samples] || 0).to_f / [result[:samples], 1].max * 100)} |

        ### Top CPU Bottlenecks

        #{top_bottlenecks_section(frames, result, :inference)}

      SECTION

      # Add wall time analysis if available
      wall_result = @results[:inference_wall]
      if wall_result
        wall_frames = extract_top_frames(wall_result)
        io_analysis = analyze_io_wait(result, wall_result)

        section += <<~WALL

          ### Wall Time Analysis

          #{io_analysis}

          ### Top Wall Time Bottlenecks

          #{top_bottlenecks_section(wall_frames, wall_result, :inference)}

        WALL
      end

      "#{section}---\n\n"
    end

    def analyze_io_wait(cpu_result, wall_result)
      cpu_result[:samples] || 1
      wall_samples = wall_result[:samples] || 1

      # Find I/O related frames in wall time
      wall_frames = extract_top_frames(wall_result)
      io_frames = wall_frames.select { |f| f[:name] =~ /IO\.|File\.|read|write|open/i }
      io_percent = io_frames.sum { |f| f[:percent] }

      # Compare CPU vs Wall for key methods
      cpu_frames = extract_top_frames(cpu_result)
      comparisons = []

      %w[Prism.parse IO.read RBS::Parser].each do |method_pattern|
        cpu_frame = cpu_frames.find { |f| f[:name]&.include?(method_pattern) }
        wall_frame = wall_frames.find { |f| f[:name]&.include?(method_pattern) }
        next unless cpu_frame && wall_frame

        cpu_pct = cpu_frame[:percent]
        wall_pct = wall_frame[:percent]
        diff = wall_pct - cpu_pct

        if diff.abs > 1.0
          comparisons << "| `#{method_pattern}` | #{format("%.1f", cpu_pct)}% | #{format("%.1f", wall_pct)}% " \
                         "| #{format("%+.1f", diff)}% |"
        end
      end

      result = "| Metric | Value |\n|--------|-------|\n"
      result += "| Wall samples | #{wall_samples} |\n"
      result += "| I/O related | #{format("%.1f", io_percent)}% |\n"

      if comparisons.any?
        result += "\n**CPU vs Wall Comparison** (methods with >1% difference):\n\n"
        result += "| Method | CPU % | Wall % | Diff |\n"
        result += "|--------|-------|--------|------|\n"
        result += comparisons.join("\n")
      end

      result
    end

    def optimization_recommendations_section
      <<~SECTION
        ## Optimization Recommendations

        See `docs/benchmark-report.md` for detailed optimization recommendations.
      SECTION
    end

    def target_description
      TARGET_DESCRIPTIONS[@target]
    end

    def extract_top_frames(result)
      return [] unless result && result[:frames]

      frames = result[:frames].map do |_frame_id, data|
        {
          name: data[:name],
          samples: data[:samples] || 0,
          total_samples: data[:total_samples] || 0,
          percent: (data[:samples] || 0).to_f / [result[:samples], 1].max * 100,
          total_percent: (data[:total_samples] || 0).to_f / [result[:samples], 1].max * 100
        }
      end
      frames.sort_by { |f| -f[:samples] }
    end

    def extract_gc_stats(result)
      return { total: 0, percent: 0.0, marking: 0, sweeping: 0 } unless result

      gc_samples = result[:gc_samples] || 0
      total = result[:samples] || 1

      # Try to find marking/sweeping from frames
      frames = result[:frames] || {}
      marking = frames.values.find { |f| f[:name] == "(marking)" }&.dig(:samples) || 0
      sweeping = frames.values.find { |f| f[:name] == "(sweeping)" }&.dig(:samples) || 0

      {
        total: gc_samples,
        percent: format("%.2f", gc_samples.to_f / total * 100),
        marking: marking,
        sweeping: sweeping
      }
    end

    def bottleneck_detail(frame, rank, _result, phase = nil)
      name = frame[:name]
      pct = format("%.1f", frame[:percent])
      samples = frame[:samples]
      info = bottleneck_info(name, phase)

      "| #{rank} | `#{name}` | #{pct}% | #{samples} | #{info[:where]} | #{info[:what]} |"
    end

    def bottleneck_info(name, phase)
      case name
      when /Prism\.parse/
        files = @location_index.stats[:files_count]
        avg = @location_index.stats[:total_nodes] / [files, 1].max
        { where: "process_file", what: "Parse source to AST (#{files} files, ~#{avg} nodes/file)" }
      when /Prism::Source#find_line/
        { where: "convert_loc", what: "Byte offset to line number, called per node" }
      when /bsearch_index/
        { where: "find_line internal", what: "Binary search for line numbers" }
      when /PrismConverter#convert_loc/
        { where: "all convert_*", what: "IR::Loc creation, triggers find_line+column" }
      when /PrismConverter#convert_class/
        { where: "convert entry point", what: "Class/module conversion with recursive methods" }
      when /PrismConverter#convert_def/
        { where: "convert_class_or_module", what: "Method definition: params+body+return" }
      when /PrismConverter#convert_call/
        { where: "convert_*", what: "Method call conversion for duck typing tracking" }
      when /PrismConverter#convert$/
        { where: "process_file", what: "Prism AST to IR node graph entry point" }
      when /LocationIndex#add/
        { where: "index_node_recursively", what: "Add node to index (hash+uniq)" }
      when /Class#new|Data#initialize/
        { where: "IR node creation", what: "Object allocation (Loc, LiteralNode, CallNode, etc.)" }
      when /\(marking\)/
        { where: "Ruby GC", what: "Marking phase: scanning live objects" }
      when /\(sweeping\)/
        { where: "Ruby GC", what: "Sweep phase: freeing dead objects" }
      else
        if phase == :inference
          { where: "inference pipeline", what: "RBS/type inference work" }
        else
          { where: "indexing pipeline", what: "AST conversion/node creation" }
        end
      end
    end

    def top_bottlenecks_section(frames, result, phase = nil)
      return "No frame data available." if frames.empty?

      # Get top 10 bottlenecks (excluding GC-related)
      top_frames = frames.reject { |f| f[:name]&.start_with?("(") }.first(10)

      header = <<~TABLE
        | Rank | Method | CPU % | Samples | Where | What |
        |------|--------|-------|---------|-------|------|
      TABLE

      rows = top_frames.each_with_index.map do |frame, idx|
        bottleneck_detail(frame, idx + 1, result, phase)
      end

      header + rows.join("\n")
    end

    def dump_files_section
      dumps = Dir.glob("tmp/stackprof-*.dump")
      return "| No profile dumps found. | |" if dumps.empty?

      dumps.map do |f|
        desc = case f
               when /all/ then "CPU profile (all phases)"
               when /indexing/ then "CPU profile (indexing)"
               when /inference/ then "CPU profile (inference)"
               when /memory/ then "Object allocation profile"
               else "Profile dump"
               end
        "| `#{f}` | #{desc} |"
      end.join("\n")
    end
  end
end

# Parse command line options
options = {
  target: "all",
  mode: "cpu",
  limit: nil,
  samples: 100,
  output: nil,
  interval: 10,
  path: nil,
  report: false
}

OptionParser.new do |opts|
  opts.banner = "Usage: #{$PROGRAM_NAME} [options]"

  opts.on("--target=TARGET", "What to profile: indexing, inference, all (default: all)") do |v|
    options[:target] = v
  end

  opts.on("--mode=MODE", "Profiling mode: cpu, wall, object (default: cpu)") do |v|
    options[:mode] = v
  end

  opts.on("--limit=N", Integer, "Max files to process") do |v|
    options[:limit] = v
  end

  opts.on("--samples=N", Integer, "Number of inference samples (default: 100)") do |v|
    options[:samples] = v
  end

  opts.on("--output=PATH", "Output file path") do |v|
    options[:output] = v
  end

  opts.on("--interval=N", Integer, "Sampling interval in microseconds (default: 10)") do |v|
    options[:interval] = v
  end

  opts.on("--path=PATH", "Project directory to profile") do |v|
    options[:path] = File.expand_path(v)
  end

  opts.on("--report", "Generate markdown report") do
    options[:report] = true
  end

  opts.on("-h", "--help", "Show this help") do
    puts opts
    exit
  end
end.parse!

runner = ProfileIndexing::Runner.new(
  target: options[:target],
  mode: options[:mode],
  limit: options[:limit],
  samples: options[:samples],
  output: options[:output],
  interval: options[:interval],
  path: options[:path],
  report: options[:report]
)

runner.run
